install_course("Data_Analysis")
install_course("Mathematical_Biostatistics_Boot_Camp")
swirl()
datasets::mtcars
install.packages("randomForest")
setwd("~/DataScienceCoursera/RPackages/Project")
heart <- read.csv("~/DataScienceCoursera/RPackages/Project/heart.csv")
View(heart)
heart <- read.csv("heart.csv")
date()
reticulate::repl_python()
python -m pip install keras
python -m pip3 install keras
reticulate::repl_python()
reticulate::repl_python()
library(keras)
trainPath = 'train.csv'
trainData = read.csv(trainPath)
testPath = "test.csv"
testData = read.csv(testPath)
arrayTrain = trainData.values
arrayTest = testData.values
X_train = arrayTrain[:,0:13]
Y_train = arrayTrain[:,13]
X_test = arrayTest[:, 0:13]
Y_test = arrayTest[:, 13]
install.packages("tensorflow")
library(keras)
library(tensorflow)
library(tensorflow)
install_tensorflow()
install.packages("tensorflow")
library(tensorflow)
library(ggplot)
library(ggplot2)
devtools::install_github("rstudio/tensorflow")
library(devtools)
install.packages("devtools")
library(devtools)
devtools::install_github("rstudio/tensorflow")
library(tensorflow)
library(keras)
devtools::find_rtools(debug = TRUE)
install_tensorflow(method = "auto")
library(tensorflow)
install_tensorflow(method = "auto")
reticulate::conda_list()
use_condaenv("r-tensorflow")
reticulate::py_config()
library(reticulate)
use_condaenv("r-tensorflow")
install_keras(
method = c("auto", "virtualenv", "conda"),
conda = "auto",
version = "default",
tensorflow = "default",
extra_packages = c("tensorflow-hub"),
...
)
conda create -n tensorflow_env tensorflow
conda activate tensorflow_env
conda --version
reticulate::repl_python()
install.packages('IRkernel')
IRkernel::installspec()
IRkernel::installspec(user = FALSE)
library(tensorflow)
detach("package:tensorflow", unload = TRUE)
reticulate::repl_python()
library(reticulate)
use_python("/usr/local/bin/python")
library(reticulate)
use_python("/Library/Frameworks/Python.framework/Versions/3.7/bin/python3")
reticulate::repl_python()
library(reticulate)
use_python("/usr/bin/python")
reticulate::repl_python()
use_python("/Users/ashwini/opt/anaconda3/bin/python3")
reticulate::repl_python()
python --version
use_python("/usr/local/bin/python3")
reticulate::repl_python()
use_python("/Users/ashwini/opt/anaconda3/bin/python")
reticulate::repl_python()
Sys.setenv(RETICULATE_PYTHON = "/Users/ashwini/opt/anaconda3/bin/python")
reticulate::repl_python()
use_python("/Users/ashwini/DataScienceCoursera/RPackages/Project/env/bin/python")
reticulate::repl_python()
Sys.setenv(RETICULATE_PYTHON = "env/bin/python")
reticulate::repl_python()
install.packages("reticulate")
install.packages("reticulate")
Sys.setenv(RETICULATE_PYTHON = "env/bin/python")
reticulate::py_config()
reticulate::repl_python()
library(keras)
library(tensorflow)
library(keras)
trainPath <- 'trainrand.csv'
trainData <- read.csv(trainPath)
testPath <- "testrand.csv"
testData <- read.csv(testPath)
library(keras)
trainPath <- 'trainrand.csv'
trainData <- read.csv(trainPath)
testPath <- "testrand.csv"
testData <- read.csv(testPath)
arrayTrain = trainData.values
arrayTest = testData.values
X_train = arrayTrain[:,0:13]
Y_train = arrayTrain[:,13]
X_test = arrayTest[:, 0:13]
Y_test = arrayTest[:, 13]
model = Sequential()
model.add(Dense(12, input_dim=13, init='uniform', activation='relu'))
model.add(Dense(12, init='uniform', activation='sigmoid', use_bias=True))
model.add(Dense(10, init='uniform', activation='sigmoid', use_bias=True))
model.add(Dense(8, init='uniform', activation='sigmoid', use_bias=True))
model.add(Dense(8, init='uniform', activation='sigmoid', use_bias=True))
model.add(Dense(1, init='uniform', activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
scores = model.evaluate(X_test, Y_test)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
plt.plot(history.history['accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Iteration')
plt.legend(['Train'], loc='upper left')
plt.show()
plt.plot(history.history['loss'])
plt.title('Mean square error')
plt.ylabel('Mean square error')
plt.xlabel('Iteration')
plt.legend(['Train'], loc='upper right')
plt.show()
arrayTrain = trainData.values
X_train = trainData[:,0:13]
Y_train = trainData[:,13]
print(trainData)
trainData$ca
X_train = trainData[,0:13]
X_train
X_train = trainData[,0:13]
Y_train = trainData[,13]
X_test = testData[, 0:13]
Y_test = testData[, 13]
model <- keras_model_sequential()
model %>%
layer_dense(12, input_dim=13, init='uniform', activation='relu')) %>%
layer_dense(12, init='uniform', activation='sigmoid', use_bias=True)) %>%
layer_dense(10, init='uniform', activation='sigmoid', use_bias=True)) %>%
layer_dense(8, init='uniform', activation='sigmoid', use_bias=True)) %>%
layer_dense(8, init='uniform', activation='sigmoid', use_bias=True)) %>%
layer_dense(1, init='uniform', activation='sigmoid'))
model <- keras_model_sequential()
model %>%
layer_dense(12, input_dim=13, init='uniform', activation='relu') %>%
layer_dense(12, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(10, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(8, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(8, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(1, init='uniform', activation='sigmoid')
model %>%
layer_dense(12, input_shape=13, init='uniform', activation='relu') %>%
layer_dense(12, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(10, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(8, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(8, init='uniform', activation='sigmoid', use_bias=True) %>%
layer_dense(1, init='uniform', activation='sigmoid')
model %>%
layer_dense(12, input_shape=13, activation='relu') %>%
layer_dense(12, activation='sigmoid', use_bias=True) %>%
layer_dense(10, activation='sigmoid', use_bias=True) %>%
layer_dense(8, activation='sigmoid', use_bias=True) %>%
layer_dense(8, activation='sigmoid', use_bias=True) %>%
layer_dense(1, activation='sigmoid')
model %>%
layer_dense(12, input_shape=c(13), activation='relu') %>%
layer_dense(12, activation='sigmoid') %>%
layer_dense(10, activation='sigmoid') %>%
layer_dense(8, activation='sigmoid') %>%
layer_dense(8, activation='sigmoid') %>%
layer_dense(1, activation='sigmoid')
summary(model)
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(13), activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
summary(model)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = (X_test, Y_test)
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(13), activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=13, activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
summary(model)
model <- keras_model_sequential()
summary(mode())
summary(model)
model %>%
layer_dense(12, input_shape=13, activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
summary(model)
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=227, activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(227), activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
X_test
dim(X_test)
library(keras)
trainPath <- 'trainrand.csv'
trainData <- read.csv(trainPath)
testPath <- "testrand.csv"
testData <- read.csv(testPath)
X_train = trainData[1:227,0:13]
Y_train = trainData[1:227,13]
X_test = testData[1:76, 0:13]
Y_test = testData[1:76, 13]
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=13, activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
X_train
trainData[1:227,0:13]
X_train = trainData[2:227,0:13]
Y_train = trainData[2:227,13]
X_train
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(13, 227), activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
#layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
#history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_data = testData)
history <- model %>% fit(
X_train, Y_train,
epochs = 30)
data.reshape(len(X_train),-1)
data.reshape(len(X_test),-1)
reshape(len(X_train),-1)
reshape(len(X_test),-1)
library(keras)
trainPath <- 'trainrand.csv'
trainData <- read.csv(trainPath)
testPath <- "testrand.csv"
testData <- read.csv(testPath)
X_train = trainData[,0:13]
Y_train = trainData[,13]
X_test = testData[, 0:13]
Y_test = testData[, 13]
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(13), activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_adam(),
metrics = c('accuracy')
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30)
library(keras)
trainPath <- 'trainrand.csv'
trainData <- read.csv(trainPath)
testPath <- "testrand.csv"
testData <- read.csv(testPath)
X_train = trainData[,0:13]
Y_train = trainData[,13]
X_test = testData[, 0:13]
Y_test = testData[, 13]
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(13), activation='relu', use_bias = TRUE) %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_adam(),
metrics = c('accuracy')
)
#history = model.fit(X_train, Y_train, nb_epoch = 500, validation_data = (X_test, Y_test))
history <- model %>% fit(
X_train, Y_train,
epochs = 30)
scores = model.evaluate(X_test, Y_test)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
model <- keras_model_sequential()
model %>%
layer_dense(12, input_shape=c(13), activation='relu') %>%
layer_dense(12, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(1, activation='sigmoid', use_bias = TRUE)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_adam(),
metrics = c('accuracy')
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30)
model <- keras_model_sequential()
model %>%
layer_dense(units = 12, input_shape=c(13), activation='relu') %>%
layer_dense(units = 12, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 1, activation='sigmoid', use_bias = TRUE)
summary(model)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_adam(),
metrics = c('accuracy')
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30)
model %>%
layer_dense(units = 12, input_shape=c(13), activation='relu') %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 1, activation='sigmoid', use_bias = TRUE)
model
model %>%
layer_dense(units = 12, input_shape=c(13), activation='relu') %>%
layer_dense(units = 12, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 1, activation='sigmoid', use_bias = TRUE)
model
library(keras)
trainPath <- 'trainrand.csv'
trainData <- read.csv(trainPath)
testPath <- "testrand.csv"
testData <- read.csv(testPath)
X_train = trainData[,0:13]
Y_train = trainData[,13]
X_test = testData[, 0:13]
Y_test = testData[, 13]
model <- keras_model_sequential()
model %>%
layer_dense(units = 12, input_shape=c(13), activation='relu') %>%
layer_dense(units = 12, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 10, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 8, activation='sigmoid', use_bias = TRUE) %>%
layer_dense(units = 1, activation='sigmoid', use_bias = TRUE)
model
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_split = 0.2)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = optimizer_adam(),
metrics = c('accuracy')
)
history <- model %>% fit(
X_train, Y_train,
epochs = 30,
validation_split = 0.2)
reticulate::repl_python()
